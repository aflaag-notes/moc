\documentclass[a4paper, 12pt]{report}

\usepackage[dvipsnames]{xcolor}

%%%%%%%%%%%%%%%%%
% Set Variables %
%%%%%%%%%%%%%%%%%

\def\useItalian{0}  % 1 = Italian, 0 = English

\def\courseName{Models of Computation}

\def\coursePrerequisites{
    \begin{itemize}
        \item Linguaggi di Programmazione
        \item Tecniche di Programmazione Funzionale ed Imperativa
    \end{itemize}
}

\def\book{TODO}

% \def\authorName{Simone Bianco}
% \def\email{bianco.simone@outlook.it}
% \def\github{https://github.com/Exyss/university-notes}
% \def\linkedin{https://www.linkedin.com/in/simone-bianco}

\def\authorName{Alessio Bandiera}
\def\email{alessio.bandiera02@gmail.com}
\def\github{https://github.com/aflaag-notes}
\def\linkedin{https://www.linkedin.com/in/alessio-bandiera-a53767223}

% Do not change

%%%%%%%%%%%%
% Packages %
%%%%%%%%%%%%

\usepackage{../../packages/Nyx/nyx-packages}
\usepackage{../../packages/Nyx/nyx-styles}
\usepackage{../../packages/Nyx/nyx-frames}
\usepackage{../../packages/Nyx/nyx-macros}
\usepackage{../../packages/Nyx/nyx-title}
\usepackage{../../packages/Nyx/nyx-intro}

%%%%%%%%%%%%%%
% Title-page %
%%%%%%%%%%%%%%

\logo{../../packages/Nyx/logo.png}

\ifx\useItalian0
    \institute{\curlyquotes{\hspace{0.25mm}Sapienza} UniversitÃ  di Roma}
    \faculty{Ingegneria dell'Informazione,\\Informatica e Statistica}
    \department{Dipartimento di Informatica}
    \subtitle{Appunti integrati con il libro \book}
    \author{\textit{Autore}\\\authorName}
\else
    \institute{\curlyquotes{\hspace{0.25mm}Sapienza} University of Rome}
    \faculty{Faculty of Information Engineering,\\Informatics and Statistics}
    \department{Department of Computer Science}
    \subtitle{Lecture notes integrated with the book \book}
    \author{\textit{Author}\\\authorName}
\fi

\title{\courseName}
\date{\today}

% \supervisor{Linus \textsc{Torvalds}}
% \context{Well, I was bored\ldots}

%%%%%%%%%%%%
% Document %
%%%%%%%%%%%%

\begin{document}
    \maketitle

    % The following style changes are valid only inside this scope 
    {
        \hypersetup{allcolors=black}
        \fancypagestyle{plain}{%
        \fancyhead{}        % clear all header fields
        \fancyfoot{}        % clear all header fields
        \fancyfoot[C]{\thepage}
        \renewcommand{\headrulewidth}{0pt}
        \renewcommand{\footrulewidth}{0pt}}

        \romantableofcontents
    }

    \introduction

    %%%%%%%%%%%%%%%%%%%%%

    \chapter{TODO}

    \section{TODO}

    \subsection{TODO}
 
    In this first section, examples will be omitted from this notes, refer to the notes of the \curlyquotes{\href{https://github.com/aflaag-notes/languages}{Linguaggi di Programmazione}} course for further details. \todo{this notes are WIP, sections WILL change}

    \begin{frameddefn}[breakable]{Lambda calculus}
        Let $\mathrm{Var}$ be the set of all possible variables; thus, the \tbf{set $\Lambda$ of all possible $\lambda$-terms} is defined by the following rules:
        \begin{gather*}
            [var] \ \dfrac{x \in \mathrm{Var}}{x \in \Lambda} \\ \\
            [appl] \ \dfrac{M \in \Lambda \quad N \in \Lambda}{M N \in \Lambda} \\ \\
            [abs] \ \dfrac{x \in \mathrm{Var} \quad M \in \Lambda}{\lambda x.M \in \Lambda}
        \end{gather*}

        The terms of the form $\lambda x.M$ are called \tbf{$\lambda$-abstractions}, and $MN$ is the function application of $M$ to $N$. Note that function application \tit{associates to the left}, therefore $$MNL = (MN)L \neq M(NL)$$

        Lambda calculus can be alternatively defined with the \href{https://en.wikipedia.org/wiki/Backus%E2%80%93Naur_form}{Backus Normal Form} (BNF), as follows: $$M, N ::= x \mid \lambda x.M \mid M N$$
    \end{frameddefn}

    Although \tit{all functions in lambda calculus are unary}, the following definition can expand this concept.

    \begin{frameddefn}{Currying}
        \tbf{Currying} (named after \href{https://en.wikipedia.org/wiki/Haskell_Curry}{Haskell Curry}) is defined as follows: $$\lambda x_1.(\ldots (\lambda x_n. y)) \equiv \lambda x_1 \ldots x_n . y$$
    \end{frameddefn}

    \begin{frameddefn}{Boundness}
        A variable is said to be \tbf{bound} if it is declared in a $\lambda$-abstraction, otherwise it is said to be \tbf{free}.

        A term that has no free variables is said to be \tbf{closed} or \tbf{combinator}.
    \end{frameddefn}

    \begin{example}[Boundness]
        Consider the following term: $$\lambda x.xy$$ In this example, $x$ is \tit{bound}, and $y$ is \tit{free}.
    \end{example}

    \begin{frameddefn}{Notable combinators}
        The following are some of the \tbf{notable combinators}:
        \begin{equation*}
            \begin{split}
                \mathrm I &\equiv \lambda x.x \\
                \mathrm K &\equiv \lambda xy.x \\
                \mathrm O &\equiv \lambda xy.y \\
                \mathrm S &\equiv \lambda xyz.xz(yz) \\
                \mathrm B &\equiv \lambda fgx.f(gx) \\
                \mathrm C &\equiv \lambda abc.acb \\
                \mathrm W &\equiv \lambda xy.xyy
            \end{split}
        \end{equation*}
    \end{frameddefn}

    \begin{frameddefn}{Free variables}
        Given a $\lambda$-term, the function $$\func{\mathrm{free}}{\Lambda}{\mathcal P(\mathrm{Var})}$$ returns the \tbf{set of free variables in $M$}, and it is defined recursively as follows:
        $$\soe{l}{
            \mathrm{free}(x) := \{x\} \\
            \mathrm{free}(MN) := \mathrm{free}(M) \cup \mathrm{free}(N) \\
            \mathrm{free}(\lambda x.M) := \mathrm{free}(M) - \{x\}
        }$$
    \end{frameddefn}

    \begin{frameddefn}{Substitution}
        The \tbf{substitution} operation is recursively defined by the following rules:
        \begin{gather*}
            x[N/x] = N \\ \\
            y[N/x] = y \\ \\
            (P Q)[N/x] = P[N/x] \ Q[N/x] \\ \\
            (\lambda t.P)[N/x] = \lambda t.(P[N/x])
        \end{gather*}

        where $M[N/x]$ means that \tit{each instance of $x$ in $M$ is replaced with $N$}. Note that \tbf{only \tbf{free variables} may be substituted}.
    \end{frameddefn}

    \begin{frameddefn}[label={inf rules}]{Inference rules}
        The following are the \tbf{inference rules} for the lambda caluclus:
        \begin{gather*}
            \rbk{\alpha} \ \lambda x.M \equiv (\lambda y.M)[y/x] \\ \\
            \rbk{\beta} \ (\lambda x.M)N \betaconv M[N/x] \\ \\
            \rbk{\mu} \ \dfrac{M \betaconv M'}{NM \betaconv NM'} \\ \\
            \rbk{\nu} \ \dfrac{M \betaconv M'}{MN \betaconv M'N} \\ \\
            \rbk{\xi} \ \dfrac{M \betaconv M'}{\lambda x.M \betaconv \lambda x.M'}
        \end{gather*}

        Note that the $\beta$-rule is effectively \tit{one step of the computation} described by the $\lambda$-term.
    \end{frameddefn}

    \begin{frameddefn}{Normal form}
         If a term can be $\beta$-reduced, it is called \tbf{$\beta$-redex}, or simply \tbf{redex} (\tit{reducible expression}), and the reduced term is called \tbf{$\beta$-reduct}, or simply \tbf{reduct}.

         If a term has no redexes, it is said to be in \tbf{normal form}.
    \end{frameddefn}

    \begin{framedobs}{Variable capture}
        Consider the following $\lambda$-term: $$(\lambda xt.tx)(\lambda t.y) \betaconv \lambda t.t(\lambda t.y)$$ Note that the two $t$s are \tit{different}. In fact, underlining the $\lambda$-abstractions to which they are bounded to can help clarifying their distinction: $$(\lambda x\underline{t}.\underline{t}x)(\lambda t.y) \betaconv \lambda \underline{t}.\underline{t}(\lambda t.y)$$ Now, consider the following $\lambda$-term, similar to the previous one: $$(\lambda xy.yx)(\lambda t.y) \betaconv \lambda y.y(\lambda t.y)$$ This $\beta$-reduction created a problem, because now the two $y$s \tit{are the same}, even though they were not originally. In fact, the previous term can be relabeled as follows: $$(\lambda x \underline y. \underline y x)(\lambda t.y) \betaconv \lambda \underline y. \underline y (\lambda t. \underline y)$$ This happened because $$\mathrm{free}(\lambda t.y) = \{y\} - \{t\} = \{y\}$$ therefore $y$ was \tbf{captured} by the $y$ that was already present in the leftmost $\lambda$-abstraction. This phenomena is called \tbf{variable capturing}, and constitutes a problem when reducing $\beta$-redexes. In particular, to reduce this second $\lambda$-abstraction, it is necessary to apply a substitution, by using the $\alpha$ rule (refer to \cref{inf rules}): $$\lambda xy.yx = \lambda x(\lambda y.yx) = \lambda x.((\lambda y.yx)[u/y]) = \lambda x.(\lambda u.ux) = \lambda x u. ux$$ which means that the $\beta$-reduction can now be performed without any issue: $$(\lambda xu.ux)(\lambda t.y) \betaconv \lambda u.u(\lambda t.y)$$ where $y$ is still free. Note that it would not have been \tit{safe} to rename the other (free) $y$, because in general \tit{renaming free variables can create capturing problems as well}. For example, $y$ could have not been substituted with $t$, as it would otherwise be captured by the $t$ in the $\lambda$-term $\lambda t.y$, as follows: $$(\lambda t.y)[t/y] =\lambda t.t$$
    \end{framedobs}

    Fortunately, variable capturing can be solved by employing the following \tit{variable naming convention}.

    \begin{frameddefn}{Variable naming convention}
        To avoid variable capturing problems, it is sufficient to follow this \tbf{variable naming convention}: \tit{bound and free variables must have \underline{different} names between them}.

        From now on, it will be assumed that any $\beta$-reduction is performed by renaming opportunely the \tbf{bound} variables, such that in each step of the computation the naming convention is followed.
    \end{frameddefn}

    \begin{frameddefn}{Tuples}
        A \tbf{tuple} of the form $$(M_1, \ldots, M_k)$$ can be represented in $\lambda$-calculus as follows: $$\lambda x.xM_1 \ldots M_k$$
    \end{frameddefn}

    To access the elements of a tuple, \tit{projectors} are used, which are defined below

    \begin{frameddefn}{Projector}
        A \tbf{projector} has the following form $$\lambda x.x\pi_j^k$$ where $$\pi_j^k \equiv \lambda x_1 \ldots x_k.x_j$$
    \end{frameddefn}

    \begin{example}[Projectors]
        Given a tuple $\lambda x.x M_1 \ldots M_k$, its $j$-th element can be accessed as follows: $$\lambda x.x \pi_j^k (\lambda x.x M_1 \ldots M_k) \betaconv (\lambda x.x M_1 \ldots M_k) \pi_j^k \betaconv \pi_j^k M_1 \ldots M_k \betaconv M_j$$
    \end{example}

    \begin{frameddefn}{Booleans}
        \tbf{Booleans} can be defined in $\lambda$-calculus as follows: $$\centeredsoe{\mathrm T \equiv \lambda xy.x \\ \mathrm F \equiv \lambda xy.y}$$
    \end{frameddefn}

    \begin{frameddefn}{Conditionals}
        \tbf{Conditionals} can be defined in $\lambda$-calculus as follows: $$\mathrm{ite} = \lambda xyz.xyz$$
    \end{frameddefn}

    Note that $\mathrm{ite}$ stands for \tit{\curlyquotes{if-then-else}}, and in fact, the term behaves exactly like a condition when used in conjunction with the $\lambda$-booleans.

    \begin{framedobs}{Conditionals}
        The term $\mathrm{ite}$ correctly behaves as a \tit{conditional} when used with $\mathrm T$ and $\mathrm F$. In fact, when used in an term such as $$\mathrm{ite} \ \mathrm C \ \mathrm A \ \mathrm B$$ if $\mathrm C$ is a $\lambda$-boolean, the term with be $\beta$-reduced to $\mathrm A$ if $\mathrm C \equiv \mathrm T$, and it will be evaluated to $\mathrm B$ if $\mathrm C \equiv \mathrm F$. Indeed
        \begin{equation*}
            \begin{split}
                \mathrm{ite} \  \mathrm T \ \mathrm A \ \mathrm B &\equiv (\lambda xyz.xyz) \ \mathrm T \ \mathrm A \ \mathrm B \\
                                                                  &\betaconv \mathrm T \ \mathrm A \ \mathrm B \\
                                                                  &\equiv (\lambda xy.x) \ \mathrm A \ \mathrm B \\
                                                                  &\betaconv \mathrm A \\
            \end{split}
        \end{equation*}
        and
        \begin{equation*}
            \begin{split}
                \mathrm{ite} \  \mathrm F \ \mathrm A \ \mathrm B &\equiv (\lambda xyz.xyz) \ \mathrm F \ \mathrm A \ \mathrm B \\
                                                                  &\betaconv \mathrm F \ \mathrm A \ \mathrm B \\
                                                                  &\equiv (\lambda xy.y) \ \mathrm A \ \mathrm B \\
                                                                  &\betaconv \mathrm B \\
            \end{split}
        \end{equation*}
    \end{framedobs}

    \begin{frameddefn}{Church numerals}
        The \tbf{Church numerals} are defined by a mapping between natural numbers $\N$ and $\lambda$-abstractions: $$\funcmap{\varphi}{\N}{\Lambda}{n}{\lambda xy. \underbrace{x ( \ldots ( x}_{n \ \mathrm{times}}y)}$$
    \end{frameddefn}

    The Church numeral corresponding to $n \in \N$ will be represented as $\underline n \in \Lambda$.

    \begin{example}[Church numerals]
        For example, the number $\underline 0$ is represented as $$\varphi(0) = \underline 0 = \lambda xy. y \equiv \mathrm F \equiv \mathrm O$$ number $\underline 1$ as $$\varphi(1) = \underline 1 = \lambda xy.xy \equiv \mathrm T \equiv \mathrm K$$ and number $\underline 2$ as $$\varphi(2) = \underline 2 = \lambda xy.xxy$$ and so on.
    \end{example}

    The following are some important $\lambda$-functions. \todo{da finire}

    \begin{frameddefn}{Fixed point}
        Given a function $\func{f}{X}{Y}$, an element $x \in X$ is said to be a \tbf{fixed point of $f$} if and only if $f(x) = x$.
    \end{frameddefn}

    \begin{example}[Fixed points]
        Given a function $f(x) = x^2 - 3x + 4$, $x = 2$ is a \tit{fixed point} of $f$, because $$f(x) = 2^2 - 3 \cdot 2 + 4 = 4 - 6 + 4 = 2 = x$$ and thus $f(x) = x$.
    \end{example}

    \begin{example}[Functions are fixed points]
        Consider the following function $$F(g) :\equiv h(x) = \soe{ll}{1 & x = 0 \\ x \cdot g(x - 1) & x > 0}$$ that takes a function as input, an returns a function $h$; for instance, plugging in the following function $$\func{\succfn}{x}{x + 1}$$ we get that $F$ returns the following function $$F(\succfn) \equiv h(x) = \soe{ll}{1 & x = 0 \\ x \cdot \succfn(x - 1) = x \cdot x = x^2 & x > 0}$$ which is the function that returns $1$ if $x = 0$, and $x^2$ otherwise.

        It's easy to check that the \tit{fixed point} of $F$ is the following function: $$\mathrm{fact}(x) := \soe{ll}{1 & x = 0 \\ x \cdot \mathrm{fact}(x - 1) & x > 0}$$ which computes the factorial of $x$, because $$F(\mathrm{fact}) \equiv h(x) = \soe{ll}{1 & x = 0 \\ x \cdot \mathrm{fact}(x -1) & x > 0 } \equiv \mathrm{fact}$$
    \end{example}

    \begin{frameddefn}{Kleene's combinator}
        The \tbf{fixed point operator}, \tbf{$\mathrm Y$ combinator} or \tbf{Kleene's combinator} (named after \href{https://it.wikipedia.org/wiki/Stephen_Kleene}{Stephen Kleene}) is defined as follows: $$\mathrm Y \equiv \lambda f.(\lambda x.f(xx))(\lambda x.f(xx))$$ The $\mathrm Y$ combinator can be alternatively defined as follows: $$\mathrm Y \equiv (\lambda xy. y(xxy))(\lambda xy.y(xxy))$$
    \end{frameddefn}

    \begin{framedprop}{Fixed point operator}
        Given a function, Kleene's combinator returns its fixed point.
    \end{framedprop}

    \begin{proof}
        If the Kleene's combinator can return the fixed point of a given function $h$, it means that $\mathrm Y h$ is $h$'s fixed point. Therefore, the statement that has to be proved is that $$h (\mathrm Y h) \equiv \mathrm Y h$$ This can be proved for both formulations of the $\mathrm Y$ combinator, as follows:
        \begin{equation*}
            \begin{split}
                \mathrm Y h &\betaconv (\lambda f .(\lambda x.f(xx)) (\lambda x.f(xx))) h \\
                            &\betaconv (\lambda x.h(xx))(\lambda x.h(xx)) \\
                            &\betaconv h(\lambda x.h(xx) \lambda x. h(xx)) \\
                            &\betaconv h (\mathrm Y h)
            \end{split}
        \end{equation*}
        and for the alternative formulation
        \begin{equation*}
            \begin{split}
                \mathrm Y h &\betaconv ((\lambda xy.y(xxy))(\lambda xy'.y'(xxy')))h \\
                            &\betaconv (\lambda y.y ((\lambda xy'.y'(xxy'))(\lambda xy''.y''(xxy''))y))h \\
                            &\betaconv h ((\lambda xy'.y'(xxy'))(\lambda xy''.y''(xxy''))h) \\
                            &\betaconv h(\mathrm Y h)
            \end{split}
        \end{equation*}
    \end{proof}

    Note that the $\mathrm Y$ combinator can be used to perform \tit{recursion} inside $\lambda$-calculus, because of the following property: $$\centeredsoe{h(\mathrm Y h) = \mathrm Y h \\ h(h(\mathrm Y h)) = h(\mathrm Y h) = \mathrm Y h \\ \vdots \\ h (\ldots (h(\mathrm Y h))) = \mathrm Y h}$$ \todo{should i go deeper?}

    % Note that a \curlyquotes{recursive function} in $\lambda$-caluclus has to take the previous case as input. For instance, consider the following function $$h := $$

    \section{Exercises}

    \begin{framedprob}{Solve for $X$}
        Find $X$ such that $$Xx = \lambda t.t (Xx)$$
    \end{framedprob}
    
    \solution{
        The term is $$X \equiv (\lambda fbt. t(fb)) X$$ because
        \begin{equation*}
            \begin{split}
                Xx &\betaconv (\lambda fbt .t(fb)) X x \\
                   &\betaconv (\lambda bt. t(Xb)) x \\
                   &\betaconv \lambda t.t(Xx)
            \end{split}
        \end{equation*}
    }
    
    \begin{framedprob}{Solve for $H$}
        Find $H$ such that $$H (\lambda x_1 x_2 x_3.P) = \lambda x_3 x_2 x_1 . P$$
    \end{framedprob}

    \solution{
        The term is $$H \equiv \lambda f x_3 x_2 x_1 . f x_1 x_2 x_3$$ because
        \begin{equation*}
            \begin{split}
                H (\lambda x_1 x_2 x_3.P) &\betaconv (\lambda f x_3 x_2 x_1 . f x_1 x_2 x_3) (\lambda x_1 x_2 x_3.P) \\
                                                  &\betaconv \lambda x_3 x_2 x_1 . (\lambda x_1 x_2 x_3.P) x_1 x_2 x_2 \\
                                                  &\betaconv \lambda x_3 x_2 x_1 .P
            \end{split}
        \end{equation*}
    }

\end{document}
